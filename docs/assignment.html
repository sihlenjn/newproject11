<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sihle Njonga">

<title>Data Science for Industry project - Data Science for Industry Assignment 2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Data Science for Industry project</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./assignment.html" aria-current="page">
 <span class="menu-text">Main assignment</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology</a>
  <ul class="collapse">
  <li><a href="#data-pre-processing" id="toc-data-pre-processing" class="nav-link" data-scroll-target="#data-pre-processing">Data pre processing</a></li>
  <li><a href="#exploratory-data-analysis" id="toc-exploratory-data-analysis" class="nav-link" data-scroll-target="#exploratory-data-analysis">Exploratory Data Analysis</a>
  <ul class="collapse">
  <li><a href="#bag-of-words-model" id="toc-bag-of-words-model" class="nav-link" data-scroll-target="#bag-of-words-model">Bag of words model</a></li>
  <li><a href="#tf-tdf-model" id="toc-tf-tdf-model" class="nav-link" data-scroll-target="#tf-tdf-model">tf-tdf model</a></li>
  </ul></li>
  <li><a href="#predictive-models" id="toc-predictive-models" class="nav-link" data-scroll-target="#predictive-models">Predictive models</a>
  <ul class="collapse">
  <li><a href="#sec-neural-network" id="toc-sec-neural-network" class="nav-link" data-scroll-target="#sec-neural-network">Neural network</a></li>
  </ul></li>
  <li><a href="#tree-based-methods" id="toc-tree-based-methods" class="nav-link" data-scroll-target="#tree-based-methods">Tree based methods</a></li>
  </ul></li>
  <li><a href="#sec-results" id="toc-sec-results" class="nav-link" data-scroll-target="#sec-results">Results</a>
  <ul class="collapse">
  <li><a href="#neural-network" id="toc-neural-network" class="nav-link" data-scroll-target="#neural-network">Neural network</a></li>
  <li><a href="#classification-trees" id="toc-classification-trees" class="nav-link" data-scroll-target="#classification-trees">Classification trees</a></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest">Random Forest</a></li>
  <li><a href="#gradient-boosted-trees" id="toc-gradient-boosted-trees" class="nav-link" data-scroll-target="#gradient-boosted-trees">Gradient Boosted trees</a></li>
  </ul></li>
  <li><a href="#discussion-and-conclusion" id="toc-discussion-and-conclusion" class="nav-link" data-scroll-target="#discussion-and-conclusion">Discussion and conclusion</a></li>
  <li><a href="#list-of-packages-used-in-r" id="toc-list-of-packages-used-in-r" class="nav-link" data-scroll-target="#list-of-packages-used-in-r">List of packages used in <code>R</code></a></li>
  <li><a href="#data-accessibility" id="toc-data-accessibility" class="nav-link" data-scroll-target="#data-accessibility">Data accessibility</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Data Science for Industry Assignment 2</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sihle Njonga </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<div class="cell">

</div>
<section id="abstract" class="level1">
<h1>Abstract</h1>
<p>Start with textmining ….</p>
<p>The State of the Nation Address of the President of South Africa (SONA) is an annual event in which the President of South Africa reports on the status of the nation, normally to the resumption of a joint sitting of Parliament. This tends to be a long speech detailing every aspect on the state of the country. In this paper, we construct and compare three predictive models that take a sentence of text as input and return a prediction of which president was the source of that sentence. The 3 predictive models which are compared are neural networks, decision tree and random forest.</p>
<p>Our findings reveal that ….</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The objective of this paper is to construct at least three predictive models that takes a sentence of text as input and return a prediction of which president was the source of the that sentence. The data set that will be used is the State of the Nation Address of the President of South Africa (SONA). The data set contains speeches of all the SONA from 1994 to 2022. This is a multi-classification problem with 6 classes since we had 6 presidents who have done speech in the specified period.</p>
<p>Th paper is divided into three main sections namely methodology , results and conclusion. The methodology sections contains 3 sub-sections outlined below:</p>
<ul>
<li><p>Data pre processing - overview of how the data was cleaned and transformed to the required form in order to apply the predictive models and also conduct Exploratory Data Analysis..</p></li>
<li><p>Exploratory Data Analysis - summary of the data set where we look at the most used words and <span class="math inline">n-</span>grams by the presidents. We also take a closer looker at president Cyril Ramaphosa speech for pre and post Covid-19 , these are the 2020 and 2021 speeches.</p></li>
<li><p>Fitted predictive models - in this subsection , we provide a brief theory behind all the predictive models fitted in our dataset and what exactly they do.</p></li>
</ul>
<p>The results section contain all the results of our</p>
</section>
<section id="methodology" class="level1">
<h1>Methodology</h1>
<section id="data-pre-processing" class="level2">
<h2 class="anchored" data-anchor-id="data-pre-processing">Data pre processing</h2>
<p>The data set is loaded in <code>R</code></p>
<div class="cell">

</div>
</section>
<section id="exploratory-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-data-analysis">Exploratory Data Analysis</h2>
<p>In this study , the SONA data set will be used. This dataset contains all the speeches of the previous presidents from 1994 to 2023 which is in the form of text file. Pre processing of the data set is conducted so that we’re able to transform the dataset into the required form. The steps taken to clean and transform the data are indicated below.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assignment_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="2400"></p>
<p></p><figcaption class="figure-caption">Top 10 mostly common used words by all presidents</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Top 10 most words used by each president.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assignment_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="2400"></p>
<p></p><figcaption class="figure-caption">Top 10 most used words by each president</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">

</div>
<p>2020 and 2021 Ramaphosa’s speeches</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="assignment_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="2400"></p>
</div>
<div class="cell-output-display">
<p><img src="assignment_files/figure-html/unnamed-chunk-6-2.png" class="img-fluid" width="2400"></p>
</div>
</div>
<div class="cell">

</div>
<section id="bag-of-words-model" class="level3">
<h3 class="anchored" data-anchor-id="bag-of-words-model">Bag of words model</h3>
<p>The machine learning algorithms that will be applied in the paper accept a certain format of text data as they cannot operate on raw text. This means the data set must be represented in a numerical form prior being feed into a machine learning algorithm. <span class="citation" data-cites="blogBagModel">Topper (<a href="#ref-blogBagModel" role="doc-biblioref">n.d.</a>)</span> The bag-of-words model is used to for this , one can think of this as a method to convert words to numerical representation.</p>
<p>In this study, we are interested to tokenizer the data into sentences rather than words. To achieve this, the data set is tokenized using token <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> as sentences. And extra column, index is added which shows the index of the sentences in the data . The tibble is further tokenized into words. The bag of words model will be based on the top 1000 most used words by the presidents. AN</p>
</section>
<section id="tf-tdf-model" class="level3">
<h3 class="anchored" data-anchor-id="tf-tdf-model">tf-tdf model</h3>
<p>This model measures the importance of a word to a document in a collection of documents ( <span class="citation" data-cites="textMiningBook">Robinson (<a href="#ref-textMiningBook" role="doc-biblioref">n.d.</a>)</span> ) This is measureed by how frequently a words occurs in a document, which is termed <em>term frequency (tf)</em>. For the bag of words model, we need to consider whether to remove stop words or not. But this model uses the approach where it looks at a term’s inverse document <em>frequency (idf),</em> this decreases the weight for commonly used words and increase the weights for those words that are not commonly used in the document. This implies for this model, we do not have remove stop words. The inverse document frequency of any given term is defined as</p>
<p><span id="eq-idf"><span class="math display">
idf(\text{term}) = \ln \left( \frac{n_{\text{docs}}}{n_{\text{docs containing term}}} \right)
\tag{1}</span></span></p>
<p>where <span class="math inline">n_{\text{docs}}</span> is the number of documents. The <code>bind_tf_idf()</code> function available on the <code>tidyverse</code> library to convert our data set to this format. <a href="#eq-idf">Equation&nbsp;1</a> can be applied if one does the conversion form first principles , which is essentially what the function is performing.</p>
</section>
</section>
<section id="predictive-models" class="level2">
<h2 class="anchored" data-anchor-id="predictive-models">Predictive models</h2>
<p>To fit the predictive models, different formats of the data sets will be used to access the performance of each model under each format. The bag-of-words format and the TF-IDF format and also other format that will take into account the issue of imbalance of the data as discussed in section ///. This aims to briefly explain the theory behind each model that will be fitted and also some packages and hyper-parameters that will used in our problem. The exact hyper-parameters are displayed in <a href="#sec-results">Section&nbsp;4</a> . For example, would be number of trees to be used for the tree based models. In the section, we wo</p>
<p>The data set will be splitted into a training set and testing set. The training set will be used to train the dataset and performance of each model will assessed on the testing set. We used a <span class="math inline">70/30</span> splitting rule, i.e.&nbsp;<span class="math inline">70\%</span> of the data will be used as the training set and <span class="math inline">30\%</span> as the testing set.</p>
<section id="sec-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="sec-neural-network">Neural network</h3>
<p>In this section , we fit a multi-layer perceptron Neural network. This network solves the shortcoming of the Feedforward Neural Network of not being able to learn through backpropagation. It is mainly used for classification problem which is exactly what we have. Since we have 6 presidents, this can be considered as a multiclassification problem with 6 classes. The fitting of the Neural Network is implemented using <code>keras</code> package in <code>R</code>. The parameters involved in fitting the model in <code>keras</code> are explained below:</p>
<p><code>keras_model_sequential()</code> This part we specify the number of layers in our model and the activation function that each must have . The activation function used depends on the type of data set in question.</p>
<p>The most common used activation functions are <code>sigmoid</code>, <code>ReLU</code> and <code>softmax</code> .</p>
<p>For the base model, we used 3 layers. For the input layer, the ReLU activation function will be used with 201 units. And for the hidden layers, we use the softmax activation will be used for output layer and ReLU activation for the input layers.</p>
<p><br>
<code>compile()</code><br>
This is the step one specify the loss function , optimizer and metrics. In our case, since this is a classification problem with 6 classes, the <code>categorical_crossentropy</code> is used. We use <code>accuracy</code> for metric and <code>adam</code> for the optimizer.</p>
<p>To fit the model, we specify the response variable and input variable and the number of <code>epochs</code> .</p>
</section>
</section>
<section id="tree-based-methods" class="level2">
<h2 class="anchored" data-anchor-id="tree-based-methods">Tree based methods</h2>
<p>The other predictive models that are considered are decision trees, which will include classification trees , random forests and gradient boosted trees. Each of these have their own advantage and disadvantage which will be explored below. The main aim to fit these tree method is to compare them to our neural network results. One of the disadvantanges of these methods is that the predictive accuracy of the trees is not as good as some other classification approaches.</p>
<p><strong>Classification trees</strong></p>
<p>Classification trees are applied to problems where the target variable is categorically which is relevant to our data set. At each step during the tree growth, a certain splitting criterion must be applied. The splitting criteria that exists in the literature are the Gini Index , Entropy and Deviance. In the paper, the Gini Index will be splitting criterion used for splitting the classification trees. The Gini Index measures the variability within the leaf nodes of a tree. At each step during tree growth, we choose a split that results in the greatest reduction of the Gini Index. The Gini Index is given by</p>
<p><span class="math display">
G =\sum_{j=1}^J G_j \quad \text{where} \quad  G_j = \sum_{k=1}^K \hat{p}_{jk}(1-\hat{p}_{jk}
)</span></p>
<p><span class="math inline">\hat{p}_{jk}</span> is the proportion of observations in the target variable <span class="math inline">k =1 ,..., K</span> within leaf node <span class="math inline">j=1,…,J</span></p>
<p>This method will be implemented using the <code>rpart()</code> package in <code>R</code> with <code>method = class</code> since this is classification problem with 6 classes i.e.&nbsp;the number of presidents in the data set. The default splitting criteria used by this package is the Gini index.</p>
<p><strong>Random Forests</strong></p>
<p>This method uses bootstrapping sampling technique to grow trees on the bootstrap samples. The predictions are made by taking the majority vote (for classification problems) i.e.&nbsp;the prediction for an observation will be one occurring mostly among the 6 categories. The method also provides an improvement by decorrelating the trees that are produced on the boostrap samples. This will be implemented by using the <code>randomForest</code> package in <code>R</code>, the difference between a classification problem and regression problem in this package is the default value for number of trees used (<code>mtry</code>). For classification problem, <span class="math inline">\text{mtry} \approx \sqrt{p}</span> and for regression problem , <span class="math inline">\text{mtry} = \frac{p}{3}</span> where <span class="math inline">p</span> is the number of predictor variables in the data set.</p>
<p><strong>Gradient Boosted Trees</strong></p>
<p>Tuning parameters for the <code>gbm</code> package:</p>
<ul>
<li><p><span class="math inline">B</span> the number of trees to grow -</p></li>
<li><p>Learning rate (<span class="math inline">\lambda</span>) -</p></li>
<li><p>Number of splits in each tree <span class="math inline">d</span> -</p></li>
</ul>
<p>In the methods stated above, one can explore the importance of the predictor variables used. However, our interest is to compare the performance of these models to the Neural Network in <a href="#sec-neural-network">Section&nbsp;3.3.1</a> section.</p>
</section>
</section>
<section id="sec-results" class="level1">
<h1>Results</h1>
<section id="neural-network" class="level2">
<h2 class="anchored" data-anchor-id="neural-network">Neural network</h2>
</section>
<section id="classification-trees" class="level2">
<h2 class="anchored" data-anchor-id="classification-trees">Classification trees</h2>
<div id="tbl-class_results" class="anchored">
<table class="table">
<caption>Table&nbsp;1: Results of the classification tree model for different data formats</caption>
<thead>
<tr class="header">
<th>Data set</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bag-of-words format</td>
<td></td>
</tr>
<tr class="even">
<td>TF-IDF format</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="random-forest" class="level2">
<h2 class="anchored" data-anchor-id="random-forest">Random Forest</h2>
<div id="tbl-randomForest_results" class="anchored">
<table class="table">
<caption>Table&nbsp;2: Results of the randomForest model for different data formats</caption>
<thead>
<tr class="header">
<th>Data set</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bag-of-words format</td>
<td></td>
</tr>
<tr class="even">
<td>TF-IDF format</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="gradient-boosted-trees" class="level2">
<h2 class="anchored" data-anchor-id="gradient-boosted-trees">Gradient Boosted trees</h2>
</section>
</section>
<section id="discussion-and-conclusion" class="level1">
<h1>Discussion and conclusion</h1>
<p>Discuss which models performed better under each type of data set used?</p>
<p>What could be improved and some future recommendations?</p>
</section>





<div id="quarto-appendix" class="default"><section id="list-of-packages-used-in-r" class="level1 appendix"><h2 class="quarto-appendix-heading">List of packages used in <code>R</code></h2><div class="quarto-appendix-contents">

<p>In this section , we includes the main packages that we used in <code>R</code> and the corresponding sections in which the packages were used. The packages have also been cited under references. We only include the package names, not the individual functions that available under each package. These are shown in <a href="#tbl-packages">Table&nbsp;3</a> . [Remove this]</p>
<div id="tbl-packages" class="anchored">
<table class="table">
<caption>Table&nbsp;3: List of packages used in the study</caption>
<colgroup>
<col style="width: 27%">
<col style="width: 72%">
</colgroup>
<thead>
<tr class="header">
<th>Package name</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>tidyverse</code></td>
<td>Data cleaning and pre-processing</td>
</tr>
<tr class="even">
<td><code>tidytext</code> <code>stingr</code></td>
<td>Manipulation of text data</td>
</tr>
<tr class="odd">
<td><code>keras</code></td>
<td>Fit a feed-forward neural network</td>
</tr>
<tr class="even">
<td><code>gridExtra</code></td>
<td>Organize multiple plots produced by the <code>ggplot</code> package to be one figure during EDA.</td>
</tr>
<tr class="odd">
<td><code>rpart</code> <code>randomForest</code> <code>gbm</code></td>
<td>Fitting a classification tree for bag of words and TF-IDF models.</td>
</tr>
<tr class="even">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div></section><section id="data-accessibility" class="level1 appendix"><h2 class="quarto-appendix-heading">Data accessibility</h2><div class="quarto-appendix-contents">

<p>The originial dataset used for this study can be found in <a href="https://www.gov.za/state-nation-address">link</a> . We have also read the individual text files of the speeches for reading the data on <code>R</code> from Ian’s github page.&nbsp;All the analysis and fitting of models in this study will conducted using the free Statistical Computing software <code>R</code>. <span class="citation" data-cites="R">R Core Team (<a href="#ref-R" role="doc-biblioref">2023</a>)</span></p>
</div></section><section id="references" class="level1 appendix"><h2 class="quarto-appendix-heading"></h2><div class="quarto-appendix-contents">




</div></section><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-R" class="csl-entry" role="doc-biblioentry">
R Core Team. 2023. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-textMiningBook" class="csl-entry" role="doc-biblioentry">
Robinson, J. S. A. D. n.d. <span>“Welcome to <span>Text</span> <span>Mining</span> with <span>R</span> <span>Text</span> <span>Mining</span> with <span>R</span>.”</span> https://www.tidytextmining.com/.
</div>
<div id="ref-blogBagModel" class="csl-entry" role="doc-biblioentry">
Topper, Noah. n.d. <span>“Bag of Words Model in NLP Explained.”</span> https://www.builtin.com/machine-learning/bag-of-words.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>A unit used to split the data in the process of tokenization.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>