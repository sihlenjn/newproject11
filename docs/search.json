[
  {
    "objectID": "assignment.html#data-pre-processing",
    "href": "assignment.html#data-pre-processing",
    "title": "Data Science for Industry Assignment 2",
    "section": "Data pre processing",
    "text": "Data pre processing\nBefore we begin with the data cleaning, we load the data by the file names. The content (texts) of each speech is then loaded to an empty vector which is created prior the beginning of the cleaning process. It worth to note the individual speech contents are take from Ian’s github page and read as characters to the empty vector. The resulting data frame has two columns filename and speech. New columns, president, year and date are added to indicate from which president the speeches are from and also the dates the speeches took place. These are generated by using the file names since each file name contains the president names and the dates of speeches. Any unnecessary text is removed from the data set, these includes website links , encoding for new lines \\n , backlashes and make sure all the dates are in the form \\text{dd-mm-yyyy}. All the speeches being with the date on which they were delivered, we remove these in the data as they are not of interest. These dates are used to generate the dates column in the data frame , the dates are removed after the dates column has been generated. A new column, named pres_num ,is also included where each president name is denoted by integers from 1 to 6. All these data cleaning procedure are conducted using the tidyverse and tidytext packages."
  },
  {
    "objectID": "assignment.html#data-analysis",
    "href": "assignment.html#data-analysis",
    "title": "Data Science for Industry Assignment 2",
    "section": "Data Analysis",
    "text": "Data Analysis\nIn order to begin with EDA, we have to tokenize the data. As much we are interested in sentences, in our EDA will tokenize the data set by words and also sentences. This will give us insights on words that are commonly used by the presidents in their speeches.\n\n\n\n\n\nFigure 1: Top 10 mostly common used words by all presidents.\n\n\n\n\nFigure 1 depicts the top 10 most used words by the 6 presidents. In Figure 1 , we see that the words government , south , people and national are the most used words by the presidents. These words are indication of what the speeches are all about.\n\n\n\n\n\n\n\n\nIn Figure 2 and ?@fig-ramaphosa_bigrams , we look at Ramaphosa’s speeches for the year 2020 and 2021. These speeches are of interest as they were made before the start of Covid-19 and after Covid-19. Upon analysing the data, sort the top words and bigrams used, we noticed that figures which were included in this speech were treated as individual words. For example, if the figure R250 000 was mentioned somewhere in the speech, R250 and 000 were treated as individual words. So after we extracted Ramaphosa’s 2020 and 2021 speeches, we cleaned the data to remove these space between the numbers. Before we did the cleaning, 000 was the most used ‘word’ in the speech for 2021 but not for 2020. This implies that a lot numbers were mentioned in Ramaphosa’s speech compared to his 2020 speech. There isn’t much difference between the words used in the 2020 and 2021 speeches in Figure 2.\n\n\n\n\n\nFigure 2: Comparison of the most used words by Ramaphosa for 2020 and 2021 speeches.\n\n\n\n\nIn Figure , this is where we notice a difference between the two speeches. As one would expect, the bi-grams Covid-19, million people and create jobs appears in the 2021 speech. The top 3 most used bi-grams are similar in both speeches.\n\n\n\n\n\nComparison of the most used bigrams by Ramaphosa for 2020 and 2021 speeches."
  },
  {
    "objectID": "assignment.html#imbalanced-data",
    "href": "assignment.html#imbalanced-data",
    "title": "Data Science for Industry Assignment 2",
    "section": "Imbalanced data",
    "text": "Imbalanced data\nIn Figure 3 , the average number of sentence for each speech is displayed for each president. We can see that deKlerk’s speech had less number of sentences on average compared to the other presidents. As much as Motlanthe had only 1 speech, but the average number of sentence in his speech was in the same range as that of Zuma, Mbeki , Mandela and Ramaphosa.\n\n\n\n\n\nFigure 3: Average number of sentences used by the presidents in their speeches.\n\n\n\n\nThis creates an imbalance in the data set as deKlerk will be under represented in the data set. This means when creating training and test set, the class represented will have less frequency compared to the other presidents. To work around this when fitting the models, we have decided to create different data sets where the row with deKlerk’s speech is removed. We compare the performance to the data set when use the data set as it is."
  },
  {
    "objectID": "assignment.html#bag-of-words-model",
    "href": "assignment.html#bag-of-words-model",
    "title": "Data Science for Industry Assignment 2",
    "section": "Bag of words model",
    "text": "Bag of words model\n\n\n\nThe machine learning algorithms that will be applied in the paper accept a certain format of text data as they cannot operate on raw text. This means the data set must be represented in a numerical form prior being feed into a machine learning algorithm. Topper (n.d.) The bag-of-words model is used to for this , one can think of this as a method to convert words to a numerical representation.\nIn this paper, we are interested to tokenizer the data into sentences rather than words. To achieve this, the data set is tokenized using tokens as sentences. An extra column is then added which shows the index of each sentence in the data. This is done in order to be able to track from which sentence do the words come from. The tibble is then further tokenized into words. The bag of words model created is based on the top 1000 most used words by the presidents."
  },
  {
    "objectID": "assignment.html#tf-tdf-model",
    "href": "assignment.html#tf-tdf-model",
    "title": "Data Science for Industry Assignment 2",
    "section": "tf-tdf model",
    "text": "tf-tdf model\n\n\n\nThis model measures the importance of a word to a document in a collection of documents ( Robinson (n.d.) ). This is measured by how frequently a words occurs in a document, which is termed term frequency (tf). For the bag of words model, we need to consider whether to remove stop words or not. But this model uses the approach where it looks at a term’s inverse document frequency (idf), this decreases the weight for commonly used words and increase the weights for those words that are not commonly used in the document. This implies for this model, we do not have remove stop words. Each term gets its own \\text{tfidf} score given by as\n\ntfidt(term) = tf(\\text{term} \\ t \\ \\text{in document}) \\times idf(\\text{term} \\ t)\n\\tag{1}\nwhere\n\nidf(\\text{term  t}) = \\ln \\left( \\frac{n_{\\text{docs}}}{n_{\\text{docs containing term $t$}}} \\right)\n\\tag{2} and \ntf(\\text{term t in document})=\\frac{\\text{Number of times $t$ appears in document $i$}}{\\text{Number of terms in document $i$}}\n\\tag{3}\nwhere n_{\\text{docs}} is the number of documents. The bind_tf_idf() function available on the tidyverse library to convert our data set to this format. Equation 2 and Equation 3 can be applied if one does the conversion form first principles , which is essentially what the function is performing.\nThe data set is converted to this format by using the tokenized data where token is set to words. The models will be fitted in both bag of words format and TF-TDF format of the data sets and compare the results based on the performance on the test set.\nTo fit the predictive models, different formats of the data sets will be used to assess the performance of each model under each format. The bag-of-words format and the TF-IDF format and also other format that will take into account the issue of imbalance of the data."
  },
  {
    "objectID": "assignment.html#predictive-models",
    "href": "assignment.html#predictive-models",
    "title": "Data Science for Industry Assignment 2",
    "section": "Predictive models",
    "text": "Predictive models\nThis section aims to briefly explain the theory behind each model that will be fitted and also some packages and parameters that are used in each model. The exact parameters are shown in Section 5 . This means, if we were to fit a tree based model that requires a certain number of trees as its parameters, th e exact value will be specified in Section 5.\nThe data set is splited into a training set and a testing set. The training set will be used to train the models and the performance of each model will assessed on the testing set. A 70/30 splitting rule is used in all the models, i.e. 70\\% of the data will be used as the training set and 30\\% as the testing set.\n\nNeural networks\nIn this section , we fit a multi-layer perceptron Neural network. It solves the shortcoming of the feedforward Neural Network of not being able to learn through back-propagation. It is mainly used for classification problems which is exactly what we have. Since we have 6 presidents, we are dealing with a multi-classification problem with 6 classes. The fitting of the Neural Network is implemented using keras package in R. The general framework for modelling using this keras is given below:\n\nDefine the model. This entails specifying the layers in the models, the input layer and output layer will always be present as these refers predictor and target variables in the data set respectively. The input shape on the input layer has to correspond to the number of predictor variables in the training set. There is also an option to add drop out rate, a float between 0 and 1.This is a regularization technique that prevents the model from over-fitting.\nEach layer must have its own activation function, this is determined by the type of data set, whether it’s continous or not. The most commonly used activation functions are SoftMax, ReLu and sigmoid.\nThe next step is to compile the model by specifying the loss function , the optimizer used and the metrics used to assess the performance of the model. For a multi-classification problem, the categorical_entropy since we have multiple classes.\nThe final step is fitting the model on the training set with a chosen number of epochs and the batch size. Predictions are then made on unseen data, the test set. The performance of the model is assessed based on the accuracy on the test set.\n\n\n\nTree based methods\nThe other predictive models that are considered are decision trees, which will include classification trees and gradient boosted trees. Each of these have their own advantage and disadvantage which will be explored below. The main aim to fit these tree method is to compare them to our neural network results. One of the disadvantages of these methods is that the predictive accuracy of the trees is not as good as some other classification approaches.\nClassification trees\nClassification trees are applied to problems where the target variable is categorically which is relevant to our data set. At each step during the tree growth, a certain splitting criterion must be applied. The splitting criteria that exists in the literature are the Gini Index , Entropy and Deviance. In the paper, the Gini Index will be splitting criterion used for splitting the classification trees. The Gini Index measures the variability within the leaf nodes of a tree. At each step during tree growth, we choose a split that results in the greatest reduction of the Gini Index. The Gini Index is given by\n\nG =\\sum_{j=1}^J G_j \\quad \\text{where} \\quad  G_j = \\sum_{k=1}^K \\hat{p}_{jk}(1-\\hat{p}_{jk}\n) \\tag{4}\n\\hat{p}_{jk} is the proportion of observations in the target variable k =1 ,..., K within leaf node j=1,…,J\nThis method will be implemented using the rpart() package in R with method = class since this is classification problem with 6 classes i.e. the number of presidents in the data set. The default splitting criteria used by this package is the Gini index.\nGradient Boosted Trees\nThe algorithm for Boosting is similar to that of Random Forest but the main different is that the trees are grown sequentially using the information from the previous trees. In RandomForests, each tree is built on a bootstrap sample independently of the other trees James et al. (2013) .The boosting algorithm does not involved boostrapp sampling , the algorithm has three main parameters:\nTuning parameters for the gbm package:\n\nB is the number of trees to grow - cross validation is used to select B since a large value of B may lead to over-fitting.\nLearning rate (\\lambda) - typical values are 0.01 or 0.001, are generally used as choices for the learning rate. The same values will be implemented in this paper.\nNumber of splits in each tree d - interaction depth of the model, the maximum number of splits the model has to perform on a tree. In most cases, d=1 works well which impiles a single is considered.\n\nIn the methods stated above, one can explore the importance of the predictor variables used. However, our interest is to compare the performance of these models to the Neural Network in Section 4.3.1 section. Hence, the importance of the variable used will not be explored."
  },
  {
    "objectID": "assignment.html#neural-network",
    "href": "assignment.html#neural-network",
    "title": "Data Science for Industry Assignment 2",
    "section": "Neural network",
    "text": "Neural network\nFour different models will be fitted. We start with a simple model, and then make modifications to the parameters as we move from one model to another to assess how the model perform which is determined by the accuracy of predictions of the test set. The models will be fitted on the original data set and also the data set where we have removed deKlerk’s speech. Throughout the paper, this model is referred to as the balanced data.The models fitted are indicated below:\n\nModel 1\n\nNumber of hidden layers = 1 , activation function used RELu with 900 units.\nInput layer : Activation function = ReLu , Units = number of rows in the training set, Inputshape =number of predictor variables.\nOutput layer : Activation function = SoftMax , units = 6 as we have 6 distinct lasses in the data set. The reason for using SoftMax it because we want to get probabilities since this is a classification problem.\n\nModel 2 This model has the same parameters as model 1 but a drop out regularization is introduce in the input layer and hidden layer to prevent over-fitting. The penalty applied is 0.05. The optimizer used for this model is rmsprop.\nModel 3 This model has the same parameters as model 1, an extra hidden layer with 1020 units. The activation function used for the extra hidden layer is the sigmoid function.\nModel 4 This model has the same parameters as model 3 but when fitting the model, the data will be scaled.\n\nIn all the models where the activation function is not specified for the any of the layers, the input layer and the hidden layers uses the ReLU activation function and the output layer uses the SoftMax activation function was used. A batch size of 5 and 40 epochs was applied, there was no improvement in the accuracy of the model for large number of epochs hence a small value is used. (Refer to a figure in the appendix as evidence, this was for model 2)\n\n\n\n\n\n\n\n\n\n\n\nTable 1: Results of the neural network models on the balanced bag of words data set\n\n\nModel\nAccuracy (original data)\nAccuracy (balance data)\n\n\n\n\nmodel 1\n0.5248\n0.5325\n\n\nmodel 2\n0.5382\n0.5481\n\n\nmodel 3\n0.5326\n0.5488\n\n\nmodel 4\n0.5136\n0.5092\n\n\n\n\nTable 1 shows the performance of the models on the out-of sample data. The model performs better on the data set where we have tried to balance the data by removing the speech of the president that had few sentence i.e. deKlerk’s speech. However, there’s no significant difference in the accuracy of all the models on both data set as they both produce an accuracy around 50\\%.\nLooking at the individual models in the balanced data, model 2 and model 3 had a higher accuracy compared to the rest of the models. This implies that changing the optimizer and adding an extra hidden layer slightly improved the performance of the models."
  },
  {
    "objectID": "assignment.html#classification-trees",
    "href": "assignment.html#classification-trees",
    "title": "Data Science for Industry Assignment 2",
    "section": "Classification trees",
    "text": "Classification trees\n\n\n\nTo fit the classification trees, we use the rpart package in R. This model will the fitted on bag of words format and also the TF-IDF format. In both cases, we will consider when using the original data and also when using the balanced data. The results of for these models are indicated in Table 2 .\n\n\nTable 2: Results of the classification tree model for different data formats\n\n\nData set\nData type used\nAccuracy\n\n\n\n\nBag-of-words format\nOriginal\n0.295\n\n\nTF-IDF format\nOriginal\n0.295\n\n\nBag-of-words format\nBalanced\n0.281\n\n\nTF-IDF format\nBalanced\n0.281\n\n\n\n\nThe models on the original data had better accuracy of 29.5\\% compared to the balanced data set. We also note that , the models attain the same accuracy irrespective of the format of the data that is used. This is cases for both the balanced and the original data. This implies that balancing the data did not make any significant improvement on the accuracy of the models. Similarly, whether we used the bag of words format or the TF-IDF format, we obtain the same accuracy of 0.295 and 0.281 respectively."
  },
  {
    "objectID": "assignment.html#gradient-boosted-trees",
    "href": "assignment.html#gradient-boosted-trees",
    "title": "Data Science for Industry Assignment 2",
    "section": "Gradient Boosted trees",
    "text": "Gradient Boosted trees\n\n\n\n\n\nTable 3: Results of the Gradient Boosted Tree model for different data formats\n\n\nData format\nData type used\nAccuracy"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome page!",
    "section": "",
    "text": "This Website contains a paper written for a course on Data Science for Industry, the paper is include in the page named main assignment. The main objective of the project is to fit at least three predictive models that take a sentence of text as input and return a prediction of which president was the source of that sentence. In this paper, tree based methods and neural networks will fitted to different formats of the data set."
  }
]